# Chinese-LLaMA-Alpaca-LoRA-Tuning
ä½¿ç”¨LoRAå¯¹Chinese-LLaMA-Alpacaè¿›è¡Œå¾®è°ƒã€‚æ•´ä½“çš„ç»“æž„éžå¸¸ç®€å•ï¼Œæž„é€ å¥½ç›¸åº”æ ¼å¼çš„æ•°æ®åŽå°±å¯ä»¥å¼€å§‹è®­ç»ƒã€‚

Facebookå®˜æ–¹å‘å¸ƒçš„[LLaMAæ¨¡åž‹ç¦æ­¢å•†ç”¨](https://github.com/facebookresearch/llama)ï¼Œå¹¶ä¸”å®˜æ–¹æ²¡æœ‰æ­£å¼å¼€æºæ¨¡åž‹æƒé‡ï¼ˆè™½ç„¶ç½‘ä¸Šå·²ç»æœ‰å¾ˆå¤šç¬¬ä¸‰æ–¹çš„ä¸‹è½½åœ°å€ï¼‰ã€‚ä¸ºäº†éµå¾ªç›¸åº”çš„è®¸å¯ï¼Œç›®å‰æš‚æ—¶æ— æ³•å‘å¸ƒå®Œæ•´çš„æ¨¡åž‹æƒé‡ï¼Œæ•¬è¯·å„ä½ç†è§£ï¼ˆç›®å‰å›½å¤–ä¹Ÿæ˜¯ä¸€æ ·ï¼‰ã€‚è‡ªè¡Œæœç´¢ä¸‹è½½åœ°å€ã€‚

è®­ç»ƒå¥½çš„å®žä½“è¯†åˆ«LoRAæƒé‡å·²ç»ä½äºŽcheckpointä¸‹ã€‚

# ä¾èµ–

linuxæ“ä½œç³»ç»Ÿä¸ºUbantuï¼ŒGPUä¸ºA40-48Gæ˜¾å­˜ã€‚

```python
mpi4py
transformers==4.28.1
peft==0.3.0
icetk
deepspeed==0.9.2
accelerate
cpm_kernels
sentencepiece==0.1.99
peft=0.3.0
torch=2.0.0 
```

# è¯´æ˜Ž

## ç›®å½•ç»“æž„

```python
--checkpointï¼šä¿å­˜æ¨¡åž‹
----msraï¼šæ•°æ®é›†åç§°
--------model_adapter
------------train_deepspeed
----------------adapter_model
--------------------adapter_config.json
--------------------adapter_model.bin
--------------------train_args.json
------------train_trainer
----------------adapter_model
--------------------adapter_config.json
--------------------adapter_model.bin
--------------------train_args.json
--model_hubï¼šé¢„è®­ç»ƒæ¨¡åž‹
----7Bï¼šè‹±æ–‡LLaMAåŽŸå§‹æƒé‡
----7B-hfï¼šè‹±æ–‡æƒé‡è½¬æ¢ä¸ºhugging faceæ ¼å¼æƒé‡
----chinese-llama-plus-lora-7bï¼šä¸­æ–‡llama-7bçš„loraæƒé‡
----chinese-alpaca-plus-lora-7bï¼šä¸­æ–‡alpaca-7bçš„loraæƒé‡
----chinese-alpaca-7bï¼šåˆå¹¶loraåŽçš„æœ€ç»ˆçš„æ¨¡åž‹
----tokenizer.modelï¼š7Bæ–‡ä»¶
----convert_llama_weights_to_hf.py
----merge_llama_with_chinese_lora.py
--dataï¼šæ•°æ®
----msraï¼šæ•°æ®é›†åç§°
--------instruct_dataï¼šæŒ‡ä»¤æ•°æ®
------------dev.txt
------------train.txt
--------ori_dataï¼šåŽŸå§‹æ•°æ®
--chat_ner.pyï¼šé—²èŠ
--train_deepspeed.pyï¼šä½¿ç”¨åŽŸç”Ÿdeepspeedè®­ç»ƒ
--train_trainer.pyï¼š ä½¿ç”¨transformersçš„Trainerè¿›è¡Œè®­ç»ƒ
--test.pyï¼šæµ‹è¯•è®­ç»ƒå¥½çš„æ¨¡åž‹
--predict.pyï¼šé¢„æµ‹
--process.pyï¼šå¤„ç†æ•°æ®ä¸ºinstruct_data
--dataset.pyï¼šåŠ è½½æ•°æ®ä¸ºç›¸åº”çš„æ ¼å¼
--deepspeed.jsonï¼šdeepspeedé…ç½®æ–‡ä»¶ï¼Œç”¨äºŽtrasnformersçš„Trainer
--config_utils.pyï¼šç”¨äºŽç”¨å­—å…¸å®šä¹‰é…ç½®ï¼Œå¹¶æŽ¥æ”¶å‘½ä»¤è¡Œå‚æ•°
```

## è½¬æ¢å¾—åˆ°ä¸­æ–‡alpaca

- 1ã€ä¸‹è½½å¥½7Bã€[llama-lora](https://huggingface.co/ziqingyang/chinese-llama-plus-lora-7b)ã€[alpaca-lora](https://huggingface.co/ziqingyang/chinese-alpaca-plus-lora-7b)åˆ°model_hubä¸‹ã€‚è¿›å…¥åˆ°model_hubç›®å½•ä¸‹ã€‚
- 2ã€å°†llamaè½¬æ¢ä¸ºhugging faceæ”¯æŒçš„æ ¼å¼ï¼š`python convert_llama_weights_to_hf.py --input_dir ./ --model_size 7B --output_dir ./7B-hf`ã€‚å¦‚æžœæŠ¥é”™ï¼š`If this call came from a _pb2.py file, your generated code is out of date and must be regenerated with protoc >= 3.19.0`åˆ™å¯ä»¥`pip install --upgrade protobuf==3.20.1`ï¼Œç„¶åŽï¼š`python convert_llama_weights_to_hf.py --input_dir ./ --model_size tokenizer_only --output_dir ./7B-hf`ã€‚æœ€ç»ˆæˆ‘ä»¬å¯ä»¥å¾—åˆ°7B-hfã€‚
- 3ã€åˆå¹¶loraåˆ°llamaä¸Šï¼š`python merge_llama_with_chinese_lora.py --base_model "./7B-hf" --lora_model "./chinese-llama-plus-lora-7b,chinese-alpaca-plus-lora-7b" --output_type "huggingface" --output_dir "./chinese-alpaca-7b" `ã€‚æœ€ç»ˆæˆ‘ä»¬å¯ä»¥å¾—åˆ°chinese-alpaca-7bã€‚
- 4ã€å›žåˆ°ä¸»ç›®å½•ï¼Œè¿›è¡Œé—²èŠéªŒè¯æ˜¯å¦å¾—åˆ°æ­£ç¡®çš„æ¨¡åž‹ï¼š`python chat_ner.py --base_model "./model_hub/chinese-alpaca-7b" --tokenizer_path "./model_hub/chinese-alpaca-7b" --with_prompt --interactive`

## æ•°æ®æ ¼å¼

è¿™é‡Œæˆ‘ä»¬ä»¥å‘½åå®žä½“è¯†åˆ«ä»»åŠ¡ä¸ºä¾‹ï¼Œæ•°æ®åœ¨data/msraä¸‹ï¼Œå…¶ä¸­ori_dataä¸ºåŽŸå§‹æ•°æ®,instruct_dataä¸ºå¤„ç†åŽçš„æ•°æ®ï¼Œæ•°æ®æ ¼å¼ä¸ºä¸€æ¡ä¸€ä¸ªæ ·æœ¬ï¼Œå…·ä½“æ˜¯ï¼š

```python
{"instruct": "ä½ çŽ°åœ¨æ˜¯ä¸€ä¸ªå®žä½“è¯†åˆ«æ¨¡åž‹ï¼Œä½ éœ€è¦æå–æ–‡æœ¬é‡Œé¢çš„äººåã€åœ°åã€æœºæž„åï¼Œå¦‚æžœå­˜åœ¨ç»“æžœï¼Œè¿”å›ž'å®žä½“_å®žä½“ç±»åž‹'ï¼Œä¸åŒå®žä½“é—´ç”¨\nåˆ†éš”ã€‚å¦‚æžœæ²¡æœ‰ç»“æžœï¼Œå›žç­”'æ²¡æœ‰'ã€‚", "query": "æ–‡æœ¬ï¼šå› æœ‰å…³æ—¥å¯‡åœ¨äº¬æŽ å¤ºæ–‡ç‰©è¯¦æƒ…ï¼Œè—ç•Œè¾ƒä¸ºé‡è§†ï¼Œä¹Ÿæ˜¯æˆ‘ä»¬æ”¶è—åŒ—äº¬å²æ–™ä¸­çš„è¦ä»¶ä¹‹ä¸€ã€‚", "answer": "æ—¥_åœ°å\näº¬_åœ°å\nåŒ—äº¬_åœ°å"}
```

å¯ä»¥æŒ‰ç…§è‡ªå·±çš„ä»»åŠ¡è‡ªè¡Œæž„å»ºã€‚

## ä¸€èˆ¬è¿‡ç¨‹

1ã€dataä¸‹æ–°å»ºæ•°æ®é›†ï¼Œç”¨process.pyå¤„ç†æ•°æ®ä¸ºinstruct_dataä¸‹çš„æ•°æ®ã€‚

2ã€è¿™é‡Œä½¿ç”¨train_trainer.pyè¿›è¡Œè®­ç»ƒï¼Œä¸ºäº†èƒ½å¤Ÿè®©transformersçš„Traineråœ¨è®­ç»ƒçš„è¿‡ç¨‹ä¸­ä¿å­˜loraæƒé‡ï¼Œå¯¹Trainerè¿›è¡Œç›¸åº”çš„ä¿®æ”¹ï¼Œå‚è€ƒï¼šhttps://github.com/huggingface/peft/issues/96 ã€‚å› ä¸ºæœ‰äº†config_utils.pyï¼Œæˆ‘ä»¬å¯ä»¥åœ¨å­—å…¸é‡Œé¢å®šä¹‰ç›¸å…³å‚æ•°ï¼Œç„¶åŽå¯ä»¥åœ¨å‘½ä»¤è¡Œä¿®æ”¹å‚æ•°çš„å€¼ï¼ˆåµŒå¥—å‚æ•°ä¹‹é—´ç”¨_åˆ†éš”ï¼‰ã€‚

```python
args = {
    "data_name": "msra",  # æ•°æ®é›†åç§°
    "model_dir": "/root/autodl-tmp/chatglm-6b/",  # chatglm-6båœ°å€ï¼Œä¿®æ”¹ä¸ºè‡ªå·±çš„è·¯å¾„
    "lora_r": 8,  # loraå‚æ•°
    "max_seq_length": 128+64,  # å¥å­æœ€å¤§é•¿åº¦
    "instruct_column": "instruct",  # instructåˆ—å
    "query_column": "query",  # queryåˆ—å
    "response_column": "answer",  # answeråˆ—å
    "train_path": "data/msra/instruct_data/train.txt", # è®­ç»ƒæ•°æ®ï¼Œä¿®æ”¹ä¸ºè‡ªå·±æ•°æ®
    "dev_path": "data/msra/instruct_data/dev.txt",  # æµ‹è¯•æ•°æ®ï¼Œä¿®æ”¹ä¸ºè‡ªå·±æ•°æ®
    "train_batch_size": 12,  # è®­ç»ƒbatch_size
    "gradient_accumulation_steps": 1,  # é»˜è®¤å°±å¥½
    "save_dir": "ã€‚/checkpoint/msra/train_trainer/",  # ä¿å­˜æ¨¡åž‹ä½ç½®ï¼Œä¿®æ”¹ä¸ºè‡ªå·±çš„è·¯å¾„
    "num_train_epochs": 1,  # è®­ç»ƒepoch
    "local_rank": -1,  # deepspeedæ‰€éœ€ï¼Œé»˜è®¤å°±å¥½
    "log_steps": 10,  # å¤šå°‘æ­¥æ‰“å°ä¸€æ¬¡ç»“æžœ
    "save_steps": 50,  # å¤šå°‘æ­¥ä¿å­˜ä¸€æ¬¡æ¨¡åž‹
    "deepspeed_json_path": "deepspeed.json" # deepspeedé…ç½®
}
```

éœ€è¦æ³¨æ„çš„æ˜¯ï¼ŒTrainerä¸­ä½¿ç”¨deepspeedè¦ä¿æŒdeepspeedå®šä¹‰çš„å‚æ•°å’ŒTraineré‡Œé¢å‚æ•°ä¿æŒä¸€è‡´ï¼Œæ¯”å¦‚ï¼šdeepspeed.jsonï¼š

```python
{
  "train_micro_batch_size_per_gpu": 12,
  "optimizer": {
    "type": "Adam",
    "params": {
      "lr": 1e-05,
      "betas": [
        0.9,
        0.95
      ],
      "eps": 1e-08,
      "weight_decay": 0.0005
    }
  },
  "fp16": {
    "enabled": true
  },
  "zero_optimization": {
    "stage": 1,
    "offload_optimizer": {
      "device": "cpu",
      "pin_memory": true
    },
    "allgather_partitions": true,
    "allgather_bucket_size": 200000000.0,
    "overlap_comm": true,
    "reduce_scatter": true,
    "reduce_bucket_size": 200000000.0,
    "contiguous_gradients": true
  }
}
```

- train_micro_batch_size_per_gpuå’Œper_device_train_batch_size
- lrå’Œlearning_rate
- betasé‡Œé¢å’Œadam_beta1ã€adam_beta2
- weight_decayå’Œweight_decay
- fp16å’Œfp16

é»˜è®¤çš„è¯ä¸ç”¨ä¿®æ”¹è¿™äº›ã€‚

## è®­ç»ƒ

```python
deeepspeed train_deepspeed.py æˆ–è€… deepspeed train_trainer.py
```

## æµ‹è¯•

ä¿®æ”¹data_nameï¼Œè¿è¡Œï¼š`python test.py`

```python
é¢„æµ‹ï¼š ['å¼€æ¥_äººå\nåŒ—äº¬å¼€æ¥å¾‹å¸ˆäº‹åŠ¡æ‰€_æœºæž„å\n', 'è¶Šç§€_æœºæž„å\n', 'ä¸­å›½å…±äº§å…š_æœºæž„å\nå‘¨æ©æ¥_äººå\né‚“é¢–è¶…_äººå\næ–°åŽæ—¥æŠ¥_æœºæž„å\n', 'æœæ¶¦å·ž_åœ°å\næ¨æ¬¡å…¬æ”¿äººå\n', 'æ™ºå‡¤_äººå\n', 'åäº”å¤§_æœºæž„å\n', 'ä¸­å›½ä¸­åŒ»ç ”ç©¶é™¢é’ˆç¸ç ”ç©¶æ‰€é—¨è¯Šéƒ¨ç™½ç™œé£Žä¸“ç§‘_æœºæž„å\nåˆ˜ç»´æž—_äººå\n', 'é•¿å®‰_åœ°å\n', 'ä¸œæ–¹è‰ºæœ¯ã€‹æ‚å¿—_æœºæž„å\nè¶Šç§€_åœ°å\n', 'è¢å´‡ç„•_äººå\n', 'å…±äº§å…š_æœºæž„å\n', 'åŒ—äº¬_åœ°å\nä¸­å›½_åœ°å\næ²ªæ²ªçº¿_åœ°å\n', 'ä¸­å›½_åœ°å\n', 'å­™_æœºæž„å\nå­™æ¯…_äººå\næ™‹å¯Ÿå†€_æ ¹æ®åœ°_åœ°å\n', 'æ¢_äººå\n', 'ä½›æ¹¾_åœ°å\n', 'ä¸­å›½_åœ°å\n', 'è‹ä¼Ÿ_äººå\n', 'ä¸­å›½_åœ°å\n', 'èš©å°¤_äººå\næ¶¿é¹¿_åœ°å\n']

çœŸå®žï¼š ['å¼€æ¥_äººå\nåŒ—äº¬å¼€æ¥å¾‹å¸ˆäº‹åŠ¡æ‰€_æœºæž„å', 'è¶Šç§€_æœºæž„å', 'ä¸­å›½å…±äº§å…š_æœºæž„å\nå‘¨æ©æ¥_äººå\né‚“é¢–è¶…_äººå\næ–°åŽæ—¥æŠ¥_æœºæž„å', 'çŸ¥æ¶¦å·ž_äººå\næ¨æ¬¡å…¬_äººå', 'èµµæ™ºå‡¤_äººå', 'åäº”å¤§_æœºæž„å', 'ä¸­å›½ä¸­åŒ»ç ”ç©¶é™¢é’ˆç¸ç ”ç©¶æ‰€é—¨è¯Šéƒ¨ç™½ç™œé£Žä¸“ç§‘_æœºæž„å\nåˆ˜ç»´æž—_äººå', 'é•¿å®‰_åœ°å', 'ã€Šä¸œæ–¹è‰ºæœ¯ã€‹æ‚å¿—_æœºæž„å\nè¶Šç§€_æœºæž„å', 'è¢å´‡ç„•_äººå', 'å…±äº§å…š_æœºæž„å', 'åŒ—äº¬_åœ°å\nä¸­å›½_åœ°å\näº¬æ²ªçº¿_åœ°å', 'ä¸­å›½_åœ°å', 'çº¢å†›_æœºæž„å\nå­™æ¯…_äººå\næ™‹å¯Ÿå†€æŠ—æ—¥æ ¹æ®åœ°_åœ°å', 'æ¢_äººå', 'ä½›æ¹¾_åœ°å', 'ä¸­å›½_åœ°å', 'è‹ä¼Ÿ_äººå', 'ä¸­å›½_åœ°å', 'èš©å°¤_äººå\næ¶¿é¹¿_åœ°å']
```

## é¢„æµ‹

ä¿®æ”¹data_nameï¼Œè¿è¡Œï¼š`python predict.py`

```python
====================================================================================================
æ–‡æœ¬ >>>  "ä½ çŽ°åœ¨æ˜¯ä¸€ä¸ªå®žä½“è¯†åˆ«æ¨¡åž‹ï¼Œä½ éœ€è¦æå–æ–‡æœ¬é‡Œé¢çš„äººåã€åœ°åã€æœºæž„åï¼Œå¦‚æžœå­˜åœ¨ç»“æžœï¼Œè¿”å›ž'å®žä½“_å®žä½“ç±»åž‹'ï¼Œä¸åŒå®žä½“é—´ç”¨\nåˆ†éš”ã€‚å¦‚æžœæ²¡æœ‰ç»“æžœï¼Œå›žç­”'æ²¡æœ‰'ã€‚æ–‡æœ¬ï¼šæˆ‘ä»¬æ˜¯å—åˆ°éƒ‘æŒ¯é“Žå…ˆç”Ÿã€é˜¿è‹±å…ˆç”Ÿè‘—ä½œçš„å¯ç¤ºï¼Œä»Žä¸ªäººæ¡ä»¶å‡ºå‘ï¼Œçž„å‡†çŽ°ä»£å‡ºç‰ˆå²ç ”ç©¶çš„ç©ºç™½ï¼Œé‡ç‚¹é›†è—è§£æ”¾åŒºã€å›½æ°‘å…šæ¯ç¦å‡ºç‰ˆç‰©ã€‚"
é¢„æµ‹ >>>  éƒ‘æŒ¯é“Ž_äººå
é˜¿è‹±_äººå
è§£æ”¾_æœºæž„å

çœŸå®ž >>>  éƒ‘æŒ¯é“Ž_äººå
é˜¿è‹±_äººå
å›½æ°‘å…š_æœºæž„å
æ–‡æœ¬ >>>  "ä½ çŽ°åœ¨æ˜¯ä¸€ä¸ªå®žä½“è¯†åˆ«æ¨¡åž‹ï¼Œä½ éœ€è¦æå–æ–‡æœ¬é‡Œé¢çš„äººåã€åœ°åã€æœºæž„åï¼Œå¦‚æžœå­˜åœ¨ç»“æžœï¼Œè¿”å›ž'å®žä½“_å®žä½“ç±»åž‹'ï¼Œä¸åŒå®žä½“é—´ç”¨\nåˆ†éš”ã€‚å¦‚æžœæ²¡æœ‰ç»“æžœï¼Œå›žç­”'æ²¡æœ‰'ã€‚æ–‡æœ¬ï¼šåŽ»å¹´ï¼Œæˆ‘ä»¬åˆè¢«è¯„ä¸ºâ€œåŒ—äº¬å¸‚é¦–å±Šå®¶åº­è—ä¹¦çŠ¶å…ƒæ˜Žæ˜Ÿæˆ·â€ã€‚"
é¢„æµ‹ >>>  åŒ—äº¬å¸‚_åœ°å

çœŸå®ž >>>  åŒ—äº¬å¸‚_åœ°å
æ–‡æœ¬ >>>  "ä½ çŽ°åœ¨æ˜¯ä¸€ä¸ªå®žä½“è¯†åˆ«æ¨¡åž‹ï¼Œä½ éœ€è¦æå–æ–‡æœ¬é‡Œé¢çš„äººåã€åœ°åã€æœºæž„åï¼Œå¦‚æžœå­˜åœ¨ç»“æžœï¼Œè¿”å›ž'å®žä½“_å®žä½“ç±»åž‹'ï¼Œä¸åŒå®žä½“é—´ç”¨\nåˆ†éš”ã€‚å¦‚æžœæ²¡æœ‰ç»“æžœï¼Œå›žç­”'æ²¡æœ‰'ã€‚æ–‡æœ¬ï¼šè—ä¹¦å®¶ã€ä½œå®¶å§œå¾·æ˜Žå…ˆç”Ÿåœ¨1997å¹´å‡ºç‰ˆçš„ä¹¦è¯ä¸“é›†ã€Šæ–‡æž—æžå¶ã€‹ä¸­ä»¥â€œçˆ±ä¹¦çš„æœ‹å‹â€ä¸ºé¢˜ï¼Œè¯¦ç»†ä»‹ç»äº†æˆ‘ä»¬å¤«å¦‡çš„è—å“åŠä¸‰å£ä¹‹å®¶ä»¥ä¹¦ä¸ºå‹ã€å¥½ä¹æ¸…è´«çš„é€¸é—»è¶£äº‹ã€‚"
é¢„æµ‹ >>>  å§œå¾·æ˜Ž_äººå

çœŸå®ž >>>  å§œå¾·æ˜Ž_äººå
```

## é—²èŠ

ä¿®æ”¹data_nameï¼Œè¿è¡Œï¼š`python chat_ner.py --base_model "./model_hub/chinese-alpaca-7b" --tokenizer_path "./model_hub/chinese-alpaca-7b" --lora_model "./checkpoint/msra/train_trainer/adapter_model" --with_prompt --interactive`

````python
+ è¯¥æ¨¡å¼ä¸‹ä»…æ”¯æŒå•è½®é—®ç­”ï¼Œæ— å¤šè½®å¯¹è¯èƒ½åŠ›ã€‚
+ å¦‚è¦è¿›è¡Œå¤šè½®å¯¹è¯ï¼Œè¯·ä½¿ç”¨llama.cppæˆ–llamachatå·¥å…·ã€‚
-------------------------------------------------------------------------------------
+ This mode only supports single-turn QA.
+ If you want to experience multi-turn dialogue, please use llama.cpp or llamachat.
=====================================================================================
Input:ä½ å¥½  
Response:  Hello!


Input:ä½ çŽ°åœ¨æ˜¯ä¸€ä¸ªå®žä½“è¯†åˆ«æ¨¡åž‹ï¼Œä½ éœ€è¦æå–æ–‡æœ¬é‡Œé¢çš„äººåã€åœ°åã€æœºæž„åï¼Œå¦‚æžœå­˜åœ¨ç»“æžœï¼Œè¿”å›ž'å®žä½“_å®žä½“ç±»åž‹'ï¼Œä¸åŒå®žä½“é—´ç”¨\nåˆ†éš”ã€‚å¦‚æžœæ²¡æœ‰ç»“æžœï¼Œå›žç­”'æ²¡æœ‰'ã€‚æ–‡æœ¬ï¼šæˆ‘ä»¬æ˜¯å—åˆ°éƒ‘æŒ¯é“Žå…ˆç”Ÿã€é˜¿è‹±å…ˆç”Ÿè‘—ä½œçš„å¯ç¤ºï¼Œä»Žä¸ªäººæ¡ä»¶å‡ºå‘ï¼Œçž„å‡†çŽ°ä»£å‡ºç‰ˆå²ç ”ç©¶çš„ç©ºç™½ï¼Œé‡ç‚¹é›†è—è§£æ”¾åŒºã€å›½æ°‘å…šæ¯ç¦å‡ºç‰ˆç‰©ã€‚
Response:  éƒ‘æŒ¯é“Ž_äººå
é˜¿è‹±_äººå


Input:ä½ çŽ°åœ¨æ˜¯ä¸€ä¸ªå®žä½“è¯†åˆ«æ¨¡åž‹ï¼Œä½ éœ€è¦æå–æ–‡æœ¬é‡Œé¢çš„äººåã€åœ°åã€æœºæž„åï¼Œå¦‚æžœå­˜åœ¨ç»“æžœï¼Œè¿”å›ž'å®žä½“_å®žä½“ç±»åž‹'ï¼Œä¸åŒå®žä½“é—´ç”¨\nåˆ†éš”ã€‚å¦‚æžœæ²¡æœ‰ç»“æžœï¼Œå›žç­”'æ²¡æœ‰'ã€‚æ–‡æœ¬ï¼šåŽ»å¹´ï¼Œæˆ‘ä»¬åˆè¢«è¯„ä¸ºâ€œåŒ—äº¬å¸‚é¦–å±Šå®¶åº­è—ä¹¦çŠ¶å…ƒæ˜Žæ˜Ÿæˆ·â€ã€‚
Response:  åŒ—äº¬å¸‚_åœ°å


Input:ä½ çŽ°åœ¨æ˜¯ä¸€ä¸ªå®žä½“è¯†åˆ«æ¨¡åž‹ï¼Œä½ éœ€è¦æå–æ–‡æœ¬é‡Œé¢çš„äººåã€åœ°åã€æœºæž„åï¼Œå¦‚æžœå­˜åœ¨ç»“æžœï¼Œè¿”å›ž'å®žä½“_å®žä½“ç±»åž‹'ï¼Œä¸åŒå®žä½“é—´ç”¨\nåˆ†éš”ã€‚å¦‚æžœæ²¡æœ‰ç»“æžœï¼Œå›žç­”'æ²¡æœ‰'ã€‚æ–‡æœ¬ï¼šè—ä¹¦å®¶ã€ä½œå®¶å§œå¾·æ˜Žå…ˆç”Ÿåœ¨1997å¹´å‡ºç‰ˆçš„ä¹¦è¯ä¸“é›†ã€Šæ–‡æž—æžå¶ã€‹ä¸­ä»¥â€œçˆ±ä¹¦çš„æœ‹å‹â€ä¸ºé¢˜ï¼Œè¯¦ç»†ä»‹ç»äº†æˆ‘ä»¬å¤«å¦‡çš„è—å“åŠä¸‰å£ä¹‹å®¶ä»¥ä¹¦ä¸ºå‹ã€å¥½ä¹æ¸…è´«çš„é€¸é—»è¶£äº‹ã€‚
Response:  å§œå¾·æ˜Ž_äººå
````

åŽŸå§‹æ¨¡åž‹ä¹Ÿå¹¶æ²¡æœ‰é€€åŒ–ã€‚

## æŠ¥é”™è§£å†³

- å®‰è£…mpi4pyæŠ¥é”™

```python
sudo apt-get update
sudo apt-get install openmpi-bin libopenmpi-dev
pip install mpi4py
```

# è¡¥å……

- **æ€Žä¹ˆè®­ç»ƒè‡ªå·±çš„æ•°æ®ï¼Ÿ**
	æŒ‰ç…§instruct_dataä¸‹çš„æ•°æ®ç»“æž„æž„é€ æ•°æ®ï¼Œå®šä¹‰å¥½ç›¸å…³å‚æ•°è¿è¡Œå³å¯ã€‚
- **æ€Žä¹ˆè¿›è¡Œé¢„æµ‹ï¼Ÿ**
	åœ¨test.pyä¸­ï¼Œé¢„æµ‹æ—¶å¯æ ¹æ®è‡ªå·±çš„ä»»åŠ¡è¿›è¡Œè§£ç ã€‚
- **ä¸ºä»€ä¹ˆä¸è¿›è¡Œè¯„ä»·æŒ‡æ ‡çš„è®¡ç®—ï¼Ÿ**
	åªæ˜¯ä½œäº†åˆæ­¥çš„è®­ç»ƒï¼Œéš¾å…æ•ˆæžœä¸å¤ªå¥½å°±ä¸è¿›è¡Œè¯„ä»·æŒ‡æ ‡çš„è®¡ç®—äº†ï¼Œå¯ä»¥åœ¨test.pyé‡Œé¢è‡ªè¡Œå®šä¹‰ã€‚

# å‚è€ƒ

> [liucongg/ChatGLM-Finetuning: åŸºäºŽChatGLM-6Bæ¨¡åž‹ï¼Œè¿›è¡Œä¸‹æ¸¸å…·ä½“ä»»åŠ¡å¾®è°ƒï¼Œæ¶‰åŠFreezeã€Loraã€P-tuningç­‰ (github.com)](https://github.com/liucongg/ChatGLM-Finetuning)
>
> [THUDM/ChatGLM-6B: ChatGLM-6B: An Open Bilingual Dialogue Language Model | å¼€æºåŒè¯­å¯¹è¯è¯­è¨€æ¨¡åž‹ (github.com)](https://github.com/THUDM/ChatGLM-6B/projects?query=is%3Aopen)
>
> [huggingface/peft: ðŸ¤— PEFT: State-of-the-art Parameter-Efficient Fine-Tuning. (github.com)](https://github.com/huggingface/peft)
>
> [ymcui/Chinese-LLaMA-Alpaca: ä¸­æ–‡LLaMA&Alpacaå¤§è¯­è¨€æ¨¡åž‹+æœ¬åœ°CPU/GPUéƒ¨ç½² (Chinese LLaMA & Alpaca LLMs) (github.com)](https://github.com/ymcui/Chinese-LLaMA-Alpaca)
